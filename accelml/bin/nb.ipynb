{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behavior</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>camera_date</th>\n",
       "      <th>camera_time</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>battery_voltage</th>\n",
       "      <th>metadata</th>\n",
       "      <th>date_time</th>\n",
       "      <th>annotation_group_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Pen11_AXY#1_S1</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>20:11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-17 16:28:28.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.985</td>\n",
       "      <td>Pen11_AXY#1_S1</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>20:11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-17 16:28:28.066667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Pen11_AXY#1_S1</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>20:11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-17 16:28:28.133334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.985</td>\n",
       "      <td>Pen11_AXY#1_S1</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>20:11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-17 16:28:28.200001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.985</td>\n",
       "      <td>Pen11_AXY#1_S1</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>20:11:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-17 16:28:28.266668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  behavior  acc_x  acc_y  acc_z          tag_id camera_date camera_time  \\\n",
       "0        s -0.016  0.031  1.000  Pen11_AXY#1_S1     3/20/18    20:11:31   \n",
       "1        s -0.016  0.047  0.985  Pen11_AXY#1_S1     3/20/18    20:11:31   \n",
       "2        s -0.016  0.031  1.000  Pen11_AXY#1_S1     3/20/18    20:11:31   \n",
       "3        s -0.016  0.031  0.985  Pen11_AXY#1_S1     3/20/18    20:11:31   \n",
       "4        s -0.016  0.016  0.985  Pen11_AXY#1_S1     3/20/18    20:11:31   \n",
       "\n",
       "   temp_c  battery_voltage  metadata                   date_time  \\\n",
       "0     NaN              NaN       NaN  2021-05-17 16:28:28.000000   \n",
       "1     NaN              NaN       NaN  2021-05-17 16:28:28.066667   \n",
       "2     NaN              NaN       NaN  2021-05-17 16:28:28.133334   \n",
       "3     NaN              NaN       NaN  2021-05-17 16:28:28.200001   \n",
       "4     NaN              NaN       NaN  2021-05-17 16:28:28.266668   \n",
       "\n",
       "   annotation_group_step  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import List, Union, Dict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import\n",
    "df = pd.read_csv(\"~/CNNworkspace/millicleantestdata.csv\")\n",
    "\n",
    "# New Time - Concatenate Date & Time fields into 1 proper datetime field\n",
    "# # making a DateTime column of the datetime type for easier manipulation\n",
    "# df[\"DateTime\"] = df.apply(\n",
    "#     lambda x: datetime.strptime(f\"{x['date']} {x['time']}\", \"%d/%m/%Y %H:%M:%S\"),\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# # Remove bad Date & Time columns\n",
    "df = df.drop([\"date\", \"time\"], axis=1)\n",
    "\n",
    "# # Get a group count to give us an anchor for iterative millisecond additions\n",
    "df[\"annotation_group_step\"] = df.groupby(\"date_time\").cumcount()\n",
    "df.head(5)\n",
    "\n",
    "# Group each datetime (each have the same second) and iteratively add 1/25 of a second\n",
    "# df[\"date_time\"] = (\n",
    "#     df.groupby(\"date_time\")\n",
    "#     .apply(\n",
    "#         lambda x: x.date_time\n",
    "#         + (timedelta(milliseconds=(1000 / x.shape[0])) * x.annotation_group_step)\n",
    "#     )\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get behavior counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t']\n"
     ]
    }
   ],
   "source": [
    "bcounts = df['behavior'].value_counts()\n",
    "bdict = bcounts.to_dict() # outputs a dict with key = behavior, value = count\n",
    " \n",
    "min_val = [keys for keys,values in bdict.items() if values == min(bdict.values())] #outputs all behaviors that have\n",
    "            #the fewest rows of data. now if the list is longer than a single value, we will test both for consecutive\n",
    "    #window length = the value_counts() of the min_val behavior\n",
    "print(min_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, 'l': 1, 't': 2, 'c': 3, 'a': 4, 'd': 5, 'i': 6, 'w': 7}\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_coder(df):\n",
    "    total_behaviors = list(df.behavior.unique())\n",
    "    num_classes = len(total_behaviors)\n",
    "    mapping = {}\n",
    "    for x in range(num_classes):\n",
    "        mapping[total_behaviors[x]] = x\n",
    "    for x in range(num_classes):\n",
    "        total_behaviors[x] = mapping[total_behaviors[x]]\n",
    "    #one_hot_encode = to_categorical(mapping[])\n",
    "    return mapping\n",
    "\n",
    "def one_hot_labeler(mapper, behavior):\n",
    "    one_hot_label = to_categorical(mapper[behavior])\n",
    "    return one_hot_label\n",
    "\n",
    "themap = one_hot_coder(df)\n",
    "print(themap)\n",
    "print(one_hot_labeler(themap,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-91e14705c135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontruct_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-91e14705c135>\u001b[0m in \u001b[0;36mcontruct_train_test\u001b[0;34m(windows)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mYtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbehavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 's'"
     ]
    }
   ],
   "source": [
    "def pull_windows(df, slide: int = 1, window_length: int = 15):\n",
    "    \"\"\" Pull matrix window \"\"\"\n",
    "    \n",
    "    # production \n",
    "    if window_length > df.shape[0]:\n",
    "        raise ValueError('Window larger than data given')\n",
    "    \n",
    "    windows = []\n",
    "    number_of_rows_minus_window = df.shape[0] - window_length + 1\n",
    "    \n",
    "    for i in range(0, number_of_rows_minus_window, slide):\n",
    "        window = df[i: i + window_length]\n",
    "            \n",
    "        # check if all behaviors are the same; if not ignore window\n",
    "        if len(set(window.behavior)) != 1:\n",
    "            continue\n",
    "        \n",
    "        # check if times are uniform -- equal length; if not ignore window\n",
    "        # if len(set(np.ediff1d(window.DateTime))) != 1:\n",
    "        #     continue\n",
    "        \n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows\n",
    "\n",
    "    \n",
    "def contruct_train_test(windows, df):\n",
    "    positions = ['acc_x', 'acc_y', 'acc_z']\n",
    "    Xtrain, Ytrain = [], []  # have to be the same length\n",
    "    # TODO - give each classifier its own index and the length should be the numpy of classifiers\n",
    "    \n",
    "    onehot = {\n",
    "        'n': [0, 0, 0, 1],  # Example: there there is only 4 classifiers in this example and we assigned 'n' to index 3\n",
    "    }\n",
    "    for window in windows:\n",
    "        Xtrain.append(window[positions].to_numpy())\n",
    "        Ytrain.append(onehot[window.behavior.values[0]])\n",
    "        \n",
    "    return np.stack(Xtrain), Ytrain\n",
    "    \n",
    "    \n",
    "windows: List[pd.DataFrame] = pull_windows(df, slide=1, window_length=10)\n",
    "\n",
    "Xtrain, Ytrain = contruct_train_test(windows, df)\n",
    "Xtrain[0], Ytrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('input.pkl', 'wb') as outfile:\n",
    "    pickle.dump((Xtrain, Ytrain), outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.016, -0.219,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.969],\n",
       "        [-0.016, -0.203,  0.969],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.219,  0.969],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.219,  0.985]]),\n",
       " [0, 0, 0, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.pkl', 'rb') as infile:\n",
    "    Xtrain, Ytrain = pickle.load(infile)\n",
    "\n",
    "Xtrain[0], Ytrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Xtrain, *args, *kwargs):\n",
    "    pass\n",
    "\n",
    "model = create_model(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(Xtrain, Ytrain)\n",
    "model.tensorflow_fuckin_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_ytest(Ytest) -> np.array:\n",
    "    pass\n",
    "\n",
    "windows = pull_windows(df, slide=1, window_length=10)\n",
    "Xtest, Ytest = contruct_train_test(windows)\n",
    "\n",
    "Ytest_predicted = model.predict(Xtest)  # may not be correct - tf.keras.model should have a predict function\n",
    "\n",
    "# Yest_predicted == Ytest?\n",
    "Ytest_predicted_fixed = fix(Ytest_predicted)  # i.e. a.index(max([0, .1, .22, .7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yay!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
