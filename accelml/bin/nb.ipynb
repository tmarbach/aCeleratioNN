{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behavior</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>camera_time</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>battery_voltage</th>\n",
       "      <th>metadata</th>\n",
       "      <th>input_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.953</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.953</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.953</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.953</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.938</td>\n",
       "      <td>JLTA_AXY#7_S1</td>\n",
       "      <td>19/05/2021</td>\n",
       "      <td>10:57:08</td>\n",
       "      <td>1:58:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  behavior  acc_x  acc_y  acc_z         tag_id        date      time  \\\n",
       "0        s  0.047  0.141  0.953  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "1        s  0.047  0.125  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "2        s  0.047  0.141  0.953  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "3        s  0.047  0.141  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "4        s  0.063  0.141  0.953  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "5        s  0.047  0.125  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "6        s  0.063  0.141  0.953  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "7        s  0.063  0.125  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "8        s  0.063  0.141  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "9        s  0.047  0.141  0.938  JLTA_AXY#7_S1  19/05/2021  10:57:08   \n",
       "\n",
       "  camera_time  temp_c  battery_voltage  metadata  input_index  \n",
       "0     1:58:42     NaN              NaN       NaN            0  \n",
       "1     1:58:42     NaN              NaN       NaN            1  \n",
       "2     1:58:42     NaN              NaN       NaN            2  \n",
       "3     1:58:42     NaN              NaN       NaN            3  \n",
       "4     1:58:42    24.0              NaN       NaN            4  \n",
       "5     1:58:42     NaN              NaN       NaN            5  \n",
       "6     1:58:42     NaN              NaN       NaN            6  \n",
       "7     1:58:42     NaN              NaN       NaN            7  \n",
       "8     1:58:42     NaN              NaN       NaN            8  \n",
       "9     1:58:42     NaN              NaN       NaN            9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import List, Union, Dict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import\n",
    "df = pd.read_csv(\"~/CNNworkspace/testdataDEC/nomil_cleanstitch.csv\")\n",
    "\n",
    "# New Time - Concatenate Date & Time fields into 1 proper datetime field\n",
    "# # making a DateTime column of the datetime type for easier manipulation\n",
    "# df[\"DateTime\"] = df.apply(\n",
    "#     lambda x: datetime.strptime(f\"{x['date']} {x['time']}\", \"%d/%m/%Y %H:%M:%S\"),\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# # Remove bad Date & Time columns\n",
    "#df = df.drop([\"date\", \"time\"], axis=1)\n",
    "\n",
    "# # Get a group count to give us an anchor for iterative millisecond additions\n",
    "\n",
    "#df[\"annotation_group_step\"] = df.groupby(\"date_time\").cumcount()\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get behavior counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "[['s']\n",
      " ['l']\n",
      " ['t']\n",
      " ['c']\n",
      " ['a']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'windowsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-93fff598b5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mediff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'windowsize' is not defined"
     ]
    }
   ],
   "source": [
    "def min_count(df):\n",
    "    \"\"\"Input: df -- dataframe of cleaned data\n",
    "    output: min_val -- single integer inside a list of the smallest number of instances\"\"\"\n",
    "    #TODO: must verify that the min values are the same behavior and continuous (index vals)\n",
    "    bcounts = df['behavior'].value_counts()\n",
    "    bdict = bcounts.to_dict() # outputs a dict with key = behavior, value = count\n",
    "\n",
    "    min_val = [values for keys,values in bdict.items() if values == min(bdict.values())] #outputs all behaviors that have\n",
    "                #the fewest rows of data. now if the list is longer than a single value, we will test both for consecutive\n",
    "        #window length = the value_counts() of the min_val behavior\n",
    "    windowsize = min_val[0]\n",
    "    return windowsize\n",
    "\n",
    "odata = df.behavior.unique()\n",
    "data = odata.reshape(-1, 1)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(len(set(np.ediff1d(df.acc_x))))\n",
    "print(data)\n",
    "print(onehot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, 'l': 1, 't': 2, 'c': 3, 'a': 4}\n",
      "[0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_coder(df):\n",
    "    total_behaviors = list(df.behavior.unique())\n",
    "    num_classes = len(total_behaviors)\n",
    "    mapping = {}\n",
    "    for x in range(num_classes):\n",
    "        mapping[total_behaviors[x]] = x\n",
    "    for x in range(num_classes):\n",
    "        total_behaviors[x] = mapping[total_behaviors[x]]\n",
    "    #one_hot_encode = to_categorical(mapping[])\n",
    "    return mapping\n",
    "\n",
    "def one_hot_labeler(mapper, behavior):\n",
    "    one_hot_label = to_categorical(mapper[behavior])\n",
    "    return one_hot_label\n",
    "\n",
    "themap = one_hot_coder(df)\n",
    "print(themap)\n",
    "print(one_hot_labeler(themap,'a'))\n",
    "\n",
    "# ndf = df.head(100)\n",
    "# pdf = pd.to_datetime(ndf['date_time'])\n",
    "# for stamp in lambda x: datetime.timestamp(x))\n",
    "# print(datetime.timestamp(pdf[1]))\n",
    "\n",
    "#ndf['date_time'] = pd.to_datetime(df['date_time']).astype(np.int64)\n",
    "#ndf['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n",
    "#ndf.int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.047 0.141 0.953]\n",
      " [0.047 0.125 0.938]\n",
      " [0.047 0.141 0.953]\n",
      " [0.047 0.141 0.938]\n",
      " [0.063 0.141 0.953]\n",
      " [0.047 0.125 0.938]\n",
      " [0.063 0.141 0.953]\n",
      " [0.063 0.125 0.938]] [0, 0, 0, 1, 0]\n",
      "[[0.047 0.125 0.938]\n",
      " [0.047 0.141 0.953]\n",
      " [0.047 0.141 0.938]\n",
      " [0.063 0.141 0.953]\n",
      " [0.047 0.125 0.938]\n",
      " [0.063 0.141 0.953]\n",
      " [0.063 0.125 0.938]\n",
      " [0.063 0.141 0.938]] [0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def pull_windows(df, slide: int = 1, window_length: int = 15):\n",
    "    \"\"\" Pull matrix window \"\"\"\n",
    "    \n",
    "    # production \n",
    "    if window_length > df.shape[0]:\n",
    "        raise ValueError('Window larger than data given')\n",
    "    \n",
    "    windows = []\n",
    "    number_of_rows_minus_window = df.shape[0] - window_length + 1\n",
    "    \n",
    "    for i in range(0, number_of_rows_minus_window, slide):\n",
    "        window = df[i: i + window_length]\n",
    "        #V\n",
    "       # dtwindow = pd.to_datetime(window['date_time'])\n",
    "        #^\n",
    "        #indarray = window['input_index'].values\n",
    "        #print(window)\n",
    "            \n",
    "        # check if all behaviors are the same; if not ignore window\n",
    "        if len(set(window.behavior)) != 1:\n",
    "            continue\n",
    "        \n",
    "        # check if times are uniform -- equal length; if not ignore window\n",
    "        \n",
    "        if len(set(np.ediff1d(window.input_index))) != 1:\n",
    "             continue\n",
    "        # len(set(np.ediff1d(window.DateTime))) != 1\n",
    "        \n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows\n",
    "\n",
    "    \n",
    "def contruct_train_test(windows, df):\n",
    "    positions = ['acc_x', 'acc_y', 'acc_z']\n",
    "    Xtrain, Ytrain = [], []  # have to be the same length\n",
    "    # TODO - give each classifier its own index and the length should be the numpy of classifiers\n",
    "    \n",
    "    onehot = {\n",
    "            's': [0, 0, 0, 1, 0],\n",
    "            'l': [0, 0, 1, 0, 0],\n",
    "            't': [0, 0, 0, 0, 1], \n",
    "            'c': [0, 1, 0, 0, 0], \n",
    "            'a': [1, 0, 0, 0, 0]\n",
    "            }\n",
    "#     {\n",
    "#         'n': [0, 0, 0, 1],  # Example: there there is only 4 classifiers in this example and we assigned 'n' to index 3\n",
    "#     }\n",
    "    for window in windows:\n",
    "        Xtrain.append(window[positions].to_numpy())\n",
    "        Ytrain.append(onehot[window.behavior.values[0]])\n",
    "        \n",
    "    return np.stack(Xtrain), Ytrain\n",
    "    \n",
    "windowsize = min_count(df)\n",
    "windows: List[pd.DataFrame] = pull_windows(df, slide=1, window_length=windowsize)\n",
    "\n",
    "Xtrain, Ytrain = contruct_train_test(windows, df)\n",
    "print(Xtrain[0], Ytrain[0])\n",
    "print(Xtrain[1], Ytrain[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('input.pkl', 'wb') as outfile:\n",
    "    pickle.dump((Xtrain, Ytrain), outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.016, -0.219,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.203,  0.969],\n",
       "        [-0.016, -0.203,  0.969],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.219,  0.969],\n",
       "        [-0.016, -0.203,  0.985],\n",
       "        [-0.016, -0.219,  0.985]]),\n",
       " [0, 0, 0, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.pkl', 'rb') as infile:\n",
    "    Xtrain, Ytrain = pickle.load(infile)\n",
    "\n",
    "Xtrain[0], Ytrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Xtrain, *args, *kwargs):\n",
    "    pass\n",
    "\n",
    "model = create_model(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(Xtrain, Ytrain)\n",
    "model.tensorflow_fuckin_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_ytest(Ytest) -> np.array:\n",
    "    pass\n",
    "\n",
    "windows = pull_windows(df, slide=1, window_length=10)\n",
    "Xtest, Ytest = contruct_train_test(windows)\n",
    "\n",
    "Ytest_predicted = model.predict(Xtest)  # may not be correct - tf.keras.model should have a predict function\n",
    "\n",
    "# Yest_predicted == Ytest?\n",
    "Ytest_predicted_fixed = fix(Ytest_predicted)  # i.e. a.index(max([0, .1, .22, .7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yay!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
